{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfYPXdmAnCRf",
        "outputId": "2abdeb2c-cf8c-4507-fb29-85265423a0d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rarfile\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: rarfile\n",
            "Successfully installed rarfile-4.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1ATotTLVBrB3tNlj4NRcV4WzqR24UUkJ3\n",
            "From (redirected): https://drive.google.com/uc?id=1ATotTLVBrB3tNlj4NRcV4WzqR24UUkJ3&confirm=t&uuid=ab043850-d328-4e2d-9e1d-05a15904e4b6\n",
            "To: /content/SDR.rar\n",
            "100%|██████████| 231M/231M [00:01<00:00, 153MB/s]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "K.clear_session()\n",
        "!pip install rarfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import rarfile\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "#\n",
        "#https://drive.google.com/file/d/1ATotTLVBrB3tNlj4NRcV4WzqR24UUkJ3/view?usp=drive_link\n",
        "#https://drive.google.com/file/d/1OGuEqyNj4aSPSW16wavw13jmp5PXS_b3/view?usp=sharing\n",
        "url = 'https://drive.google.com/uc?id=1ATotTLVBrB3tNlj4NRcV4WzqR24UUkJ3'\n",
        "output_rar = '/content/SDR.rar'\n",
        "gdown.download(url, output_rar, quiet=False)\n",
        "# Extract the RAR file\n",
        "with rarfile.RarFile(output_rar, 'r') as rar_ref:\n",
        "    rar_ref.extractall('/content')\n",
        "# Path to the extracted dataset folder\n",
        "dataset_folder = '/content/SDR'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dense169**"
      ],
      "metadata": {
        "id": "SjDYJ6CfwDjs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qkxLByJFwAM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet169\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define parameters\n",
        "input_shape = (224, 224, 3)  # Input shape for DenseNet-169\n",
        "num_classes = 2  # Adjust this to match the number of classes in your dataset\n",
        "batch_size = 32\n",
        "img_size = (224, 224)  # Image size\n",
        "best_weights_path = '/content/Split/Save/best_model.keras'  # Path to save the best weights\n",
        "train_dir = '/content/SDS/Train'  # Path to training data\n",
        "test_dir = '/content/SDS/Test'  # Path to testing data\n",
        "\n",
        "# Initialize the DenseNet-169 model with pretrained weights and custom top\n",
        "base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# Freeze the base model layers for transfer learning\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation for training data\n",
        "data_gen_train = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Preprocessing for test data\n",
        "data_gen_test = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Create data generators\n",
        "train_data_generator = data_gen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_data_generator = data_gen_test.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(best_weights_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_generator,\n",
        "    validation_data=test_data_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# Unfreeze all layers and fine-tune\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Continue training with fine-tuning\n",
        "history_fine_tune = model.fit(\n",
        "    train_data_generator,\n",
        "    validation_data=test_data_generator,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# Load the best saved weights\n",
        "model.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating the model on test data...\")\n",
        "y_true = test_data_generator.classes\n",
        "y_pred = np.argmax(model.predict(test_data_generator), axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Test Precision:\", precision)\n",
        "print(\"Test Recall:\", recall)\n",
        "print(\"Test F1-score:\", f1)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvX3Oi5unwjO",
        "outputId": "e9bb8d03-5afd-4ca2-9298-0d12ce7d870d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m51877672/51877672\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Found 3340 images belonging to 2 classes.\n",
            "Found 836 images belonging to 2 classes.\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - accuracy: 0.7542 - loss: 0.4984\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87679, saving model to /content/Split/Save/best_model.keras\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 1s/step - accuracy: 0.7550 - loss: 0.4972 - val_accuracy: 0.8768 - val_loss: 0.3107\n",
            "Epoch 2/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 0.9143 - loss: 0.2353\n",
            "Epoch 2: val_accuracy did not improve from 0.87679\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 480ms/step - accuracy: 0.9143 - loss: 0.2353 - val_accuracy: 0.8756 - val_loss: 0.2890\n",
            "Epoch 3/20\n",
            "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.9206 - loss: 0.2223\n",
            "Epoch 3: val_accuracy improved from 0.87679 to 0.88876, saving model to /content/Split/Save/best_model.keras\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 452ms/step - accuracy: 0.9207 - loss: 0.2220 - val_accuracy: 0.8888 - val_loss: 0.2589\n",
            "Epoch 4/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.9281 - loss: 0.1864\n",
            "Epoch 4: val_accuracy improved from 0.88876 to 0.93182, saving model to /content/Split/Save/best_model.keras\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 454ms/step - accuracy: 0.9280 - loss: 0.1864 - val_accuracy: 0.9318 - val_loss: 0.1889\n",
            "Epoch 5/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.9264 - loss: 0.1915\n",
            "Epoch 5: val_accuracy did not improve from 0.93182\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 444ms/step - accuracy: 0.9264 - loss: 0.1914 - val_accuracy: 0.9175 - val_loss: 0.2033\n",
            "Epoch 6/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.9324 - loss: 0.1710\n",
            "Epoch 6: val_accuracy did not improve from 0.93182\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 437ms/step - accuracy: 0.9324 - loss: 0.1710 - val_accuracy: 0.9031 - val_loss: 0.2474\n",
            "Epoch 7/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.9347 - loss: 0.1635\n",
            "Epoch 7: val_accuracy improved from 0.93182 to 0.93780, saving model to /content/Split/Save/best_model.keras\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 457ms/step - accuracy: 0.9346 - loss: 0.1636 - val_accuracy: 0.9378 - val_loss: 0.1768\n",
            "Epoch 8/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.9273 - loss: 0.1832\n",
            "Epoch 8: val_accuracy did not improve from 0.93780\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 439ms/step - accuracy: 0.9273 - loss: 0.1831 - val_accuracy: 0.9175 - val_loss: 0.2177\n",
            "Epoch 9/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.9468 - loss: 0.1440\n",
            "Epoch 9: val_accuracy did not improve from 0.93780\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 450ms/step - accuracy: 0.9468 - loss: 0.1442 - val_accuracy: 0.9306 - val_loss: 0.1778\n",
            "Epoch 10/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436ms/step - accuracy: 0.9388 - loss: 0.1618\n",
            "Epoch 10: val_accuracy did not improve from 0.93780\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 471ms/step - accuracy: 0.9388 - loss: 0.1618 - val_accuracy: 0.9294 - val_loss: 0.1878\n",
            "Epoch 11/20\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437ms/step - accuracy: 0.9395 - loss: 0.1659\n",
            "Epoch 11: val_accuracy did not improve from 0.93780\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 463ms/step - accuracy: 0.9395 - loss: 0.1657 - val_accuracy: 0.9163 - val_loss: 0.2224\n",
            "Epoch 12/20\n",
            "\u001b[1m104/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 426ms/step - accuracy: 0.9375 - loss: 0.1616\n",
            "Epoch 12: val_accuracy did not improve from 0.93780\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 449ms/step - accuracy: 0.9377 - loss: 0.1613 - val_accuracy: 0.9115 - val_loss: 0.2449\n",
            "Epoch 12: early stopping\n",
            "Epoch 1/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9018 - loss: 0.2986\n",
            "Epoch 1: val_accuracy did not improve from 0.93780\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 2s/step - accuracy: 0.9020 - loss: 0.2981 - val_accuracy: 0.9127 - val_loss: 0.2645\n",
            "Epoch 2/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531ms/step - accuracy: 0.9519 - loss: 0.1427\n",
            "Epoch 2: val_accuracy did not improve from 0.93780\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 557ms/step - accuracy: 0.9519 - loss: 0.1426 - val_accuracy: 0.9031 - val_loss: 0.2931\n",
            "Epoch 3/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - accuracy: 0.9708 - loss: 0.0806\n",
            "Epoch 3: val_accuracy improved from 0.93780 to 0.96292, saving model to /content/Split/Save/best_model.keras\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 607ms/step - accuracy: 0.9708 - loss: 0.0806 - val_accuracy: 0.9629 - val_loss: 0.1048\n",
            "Epoch 4/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - accuracy: 0.9721 - loss: 0.0721\n",
            "Epoch 4: val_accuracy did not improve from 0.96292\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 569ms/step - accuracy: 0.9721 - loss: 0.0721 - val_accuracy: 0.9462 - val_loss: 0.1675\n",
            "Epoch 5/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - accuracy: 0.9810 - loss: 0.0586\n",
            "Epoch 5: val_accuracy improved from 0.96292 to 0.97368, saving model to /content/Split/Save/best_model.keras\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 582ms/step - accuracy: 0.9809 - loss: 0.0586 - val_accuracy: 0.9737 - val_loss: 0.0881\n",
            "Epoch 6/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.9808 - loss: 0.0497\n",
            "Epoch 6: val_accuracy did not improve from 0.97368\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 561ms/step - accuracy: 0.9808 - loss: 0.0498 - val_accuracy: 0.9689 - val_loss: 0.0898\n",
            "Epoch 7/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533ms/step - accuracy: 0.9832 - loss: 0.0475\n",
            "Epoch 7: val_accuracy did not improve from 0.97368\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 558ms/step - accuracy: 0.9832 - loss: 0.0476 - val_accuracy: 0.9713 - val_loss: 0.0955\n",
            "Epoch 8/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.9788 - loss: 0.0545\n",
            "Epoch 8: val_accuracy did not improve from 0.97368\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 559ms/step - accuracy: 0.9788 - loss: 0.0546 - val_accuracy: 0.9605 - val_loss: 0.1342\n",
            "Epoch 9/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - accuracy: 0.9822 - loss: 0.0537\n",
            "Epoch 9: val_accuracy did not improve from 0.97368\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 562ms/step - accuracy: 0.9822 - loss: 0.0538 - val_accuracy: 0.9665 - val_loss: 0.1090\n",
            "Epoch 10/10\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - accuracy: 0.9835 - loss: 0.0365\n",
            "Epoch 10: val_accuracy improved from 0.97368 to 0.97847, saving model to /content/Split/Save/best_model.keras\n",
            "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 602ms/step - accuracy: 0.9836 - loss: 0.0364 - val_accuracy: 0.9785 - val_loss: 0.1002\n",
            "Evaluating the model on test data...\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 540ms/step\n",
            "Test Accuracy: 0.9784688995215312\n",
            "Test Precision: 0.9784855638331398\n",
            "Test Recall: 0.9784688995215312\n",
            "Test F1-score: 0.9784716180948239\n",
            "Confusion Matrix:\n",
            "[[431  10]\n",
            " [  8 387]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet50v2**"
      ],
      "metadata": {
        "id": "E1OaFcch3KbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define parameters\n",
        "input_shape = (224, 224, 3)  # Input shape for ResNet50V2\n",
        "num_classes = 2  # Adjust this to match the number of classes in your dataset\n",
        "batch_size = 32\n",
        "img_size = (224, 224)  # Image size\n",
        "best_weights_path = '/content/Split/Save/best_model.keras'  # Path to save the best weights\n",
        "train_dir = '/content/SDS/Train'  # Path to training data\n",
        "test_dir = '/content/SDS/Test'  # Path to testing data\n",
        "\n",
        "# Initialize the ResNet50V2 model with pretrained weights and custom top\n",
        "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "# Freeze the base model layers for transfer learning\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation for training data\n",
        "data_gen_train = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Preprocessing for test data\n",
        "data_gen_test = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Create data generators\n",
        "train_data_generator = data_gen_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_data_generator = data_gen_test.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(best_weights_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_generator,\n",
        "    validation_data=test_data_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# Unfreeze all layers and fine-tune\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile with a lower learning rate for fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Continue training with fine-tuning\n",
        "history_fine_tune = model.fit(\n",
        "    train_data_generator,\n",
        "    validation_data=test_data_generator,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint, early_stopping]\n",
        ")\n",
        "\n",
        "# Load the best saved weights\n",
        "model.load_weights(best_weights_path)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Evaluating the model on test data...\")\n",
        "y_true = test_data_generator.classes\n",
        "y_pred = np.argmax(model.predict(test_data_generator), axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Test Precision:\", precision)\n",
        "print(\"Test Recall:\", recall)\n",
        "print(\"Test F1-score:\", f1)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "MfSY9DGP0UGc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}